{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f9936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty Quantification for Brain Tumor Classification\n",
    "# Methods: Softmax, MC Dropout, Deep Ensemble, EDL, TTDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04567d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "# from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e26f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "252ca7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc55a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n"
     ]
    }
   ],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # adjust if images are RGB\n",
    "])\n",
    "\n",
    "# Paths\n",
    "base_dir = \"../data/\"\n",
    "train_folder = \"../data/Training\"\n",
    "test_folder = \"../data/Testing\"\n",
    "\n",
    "# Load datasets\n",
    "train_ds = datasets.ImageFolder(root=train_folder, transform=transform)\n",
    "test_ds = datasets.ImageFolder(root=test_folder, transform=transform)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "# Class names\n",
    "class_names = train_ds.classes\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3548b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorCNN(nn.Module):\n",
    "    def __init__(self, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2), nn.Dropout(dropout_p),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2), nn.Dropout(dropout_p),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2), nn.Dropout(dropout_p)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 28 * 28, 512), nn.ReLU(), nn.Dropout(dropout_p),\n",
    "            nn.Linear(512, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc771674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=5):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2088e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation Metrics ---\n",
    "def compute_entropy(probs):\n",
    "    return -np.sum(probs * np.log(probs + 1e-8), axis=1)\n",
    "\n",
    "def compute_ece(probs, labels, n_bins=15):\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    confidences = np.max(probs, axis=1)\n",
    "    predictions = np.argmax(probs, axis=1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        bin_lower, bin_upper = bin_boundaries[i], bin_boundaries[i+1]\n",
    "        in_bin = (confidences >= bin_lower) & (confidences < bin_upper)\n",
    "        if np.any(in_bin):\n",
    "            acc = np.mean(predictions[in_bin] == labels[in_bin])\n",
    "            avg_conf = np.mean(confidences[in_bin])\n",
    "            ece += np.abs(avg_conf - acc) * np.mean(in_bin)\n",
    "    return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a15ed6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, probs, labels):\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    acc = (preds == labels).sum() / len(labels)\n",
    "    entropy = np.mean(compute_entropy(probs))\n",
    "    ece = compute_ece(probs, labels)\n",
    "    return {\"Method\": name, \"Accuracy\": f\"{acc*100:.2f}%\", \"Avg. Entropy ↓\": f\"{entropy:.2f}\", \"ECE ↓\": f\"{ece:.2f}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8e4c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    probs, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            out = F.softmax(model(x), dim=1).cpu().numpy()\n",
    "            probs.append(out)\n",
    "            labels.extend(y.numpy())\n",
    "    return np.vstack(probs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad6bed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prediction Wrappers ---\n",
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    probs, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            out = F.softmax(model(x), dim=1).cpu().numpy()\n",
    "            probs.append(out)\n",
    "            labels.extend(y.numpy())\n",
    "    return np.vstack(probs), np.array(labels)\n",
    "\n",
    "def predict_mc_dropout(model, loader, T=50):\n",
    "    model.train()\n",
    "    probs_mc = []\n",
    "    for _ in range(T):\n",
    "        probs, _ = predict(model, loader)\n",
    "        probs_mc.append(probs)\n",
    "    return np.mean(np.stack(probs_mc), axis=0)\n",
    "\n",
    "def predict_ttda(model, loader, T=50):\n",
    "    aug = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "    dataset_aug = datasets.ImageFolder(os.path.join(base_dir, \"Testing\"), transform=aug)\n",
    "    loader_aug = DataLoader(dataset_aug, batch_size=32, shuffle=False)\n",
    "    return predict_mc_dropout(model, loader_aug, T)\n",
    "\n",
    "def predict_ensemble(models, loader):\n",
    "    all_probs = [predict(m, loader)[0] for m in models]\n",
    "    return np.mean(np.stack(all_probs), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08766056",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = train_model(BrainTumorCNN(), train_loader)\n",
    "probs, labels = predict(base_model, test_loader)\n",
    "results.append(evaluate_model(\"Softmax\", probs, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "410d4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_probs = predict_mc_dropout(base_model, test_loader)\n",
    "results.append(evaluate_model(\"MC Dropout\", mc_probs, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b8928b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttda_probs = predict_ttda(base_model, test_loader)\n",
    "results.append(evaluate_model(\"TTDA\", ttda_probs, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd287e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models = []\n",
    "for _ in range(3):\n",
    "    m = BrainTumorCNN().to(device)\n",
    "    optimizer = torch.optim.Adam(m.parameters(), lr=1e-3)\n",
    "    m.train()\n",
    "    for epoch in range(5):\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = nn.CrossEntropyLoss()(m(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    ensemble_models.append(m)\n",
    "ens_probs = predict_ensemble(ensemble_models, test_loader)\n",
    "results.append(evaluate_model(\"Deep Ensemble\", ens_probs, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c533123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Accuracy Avg. Entropy ↓ ECE ↓\n",
      "Method                                          \n",
      "Softmax (Baseline)   85.51%           0.37  0.01\n",
      "MC Dropout           85.51%           0.37  0.01\n",
      "TTDA (Optional)      82.61%           0.44  0.01\n",
      "Deep Ensemble        88.02%           0.46  0.06\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).set_index(\"Method\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fabab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evidential Deep Learning ---\n",
    "def relu_evidence(logits): return F.relu(logits)\n",
    "\n",
    "def KL_divergence(alpha):\n",
    "    K = alpha.shape[1]\n",
    "    beta = torch.ones((1, K)).to(alpha.device)\n",
    "    S_alpha = torch.sum(alpha, dim=1, keepdim=True)\n",
    "    S_beta = torch.sum(beta, dim=1, keepdim=True)\n",
    "    lnB = torch.lgamma(S_alpha) - torch.sum(torch.lgamma(alpha), dim=1, keepdim=True)\n",
    "    lnB_uni = torch.sum(torch.lgamma(beta), dim=1, keepdim=True) - torch.lgamma(S_beta)\n",
    "    dg0 = torch.digamma(S_alpha)\n",
    "    dg1 = torch.digamma(alpha)\n",
    "    kl = torch.sum((alpha - beta) * (dg1 - dg0), dim=1, keepdim=True)\n",
    "    return (kl + lnB + lnB_uni).mean()\n",
    "\n",
    "def edl_mse_loss(p, alpha, global_step, annealing_step):\n",
    "    S = torch.sum(alpha, dim=1, keepdim=True)\n",
    "    label = F.one_hot(p, num_classes=alpha.size(1)).float()\n",
    "    A = torch.sum((label - (alpha / S)) ** 2, dim=1, keepdim=True)\n",
    "    B = torch.sum(alpha * (S - alpha) / (S * S * (S + 1)), dim=1, keepdim=True)\n",
    "    annealing_coef = min(1.0, global_step / annealing_step)\n",
    "    return (A + B).mean() + annealing_coef * KL_divergence(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de1660de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EDL Inference ---\n",
    "class BrainTumorEDL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = BrainTumorCNN().features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 28 * 28, 512), nn.ReLU(),\n",
    "            nn.Linear(512, 4)  # no softmax\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "def predict_edl(model, loader):\n",
    "    model.eval()\n",
    "    probs, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            evidence = relu_evidence(logits)\n",
    "            alpha = evidence + 1\n",
    "            prob = alpha / torch.sum(alpha, dim=1, keepdim=True)\n",
    "            probs.append(prob.cpu().numpy())\n",
    "            labels.extend(y.numpy())\n",
    "    return np.vstack(probs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e680a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "edl_model = BrainTumorEDL().to(device)\n",
    "optimizer = torch.optim.Adam(edl_model.parameters(), lr=1e-3)\n",
    "edl_model.train()\n",
    "global_step = 0\n",
    "for epoch in range(10):\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = edl_model(x)\n",
    "        evidence = relu_evidence(logits)\n",
    "        alpha = evidence + 1\n",
    "        loss = edl_mse_loss(y, alpha, global_step, annealing_step=100)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "edl_probs, edl_labels = predict_edl(edl_model, test_loader)\n",
    "results = results[:4]\n",
    "results.append(evaluate_model(\"EDL\", edl_probs, edl_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94ecca78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Method': 'Softmax (Baseline)',\n",
       "  'Accuracy': '85.51%',\n",
       "  'Avg. Entropy ↓': '0.37',\n",
       "  'ECE ↓': '0.01'},\n",
       " {'Method': 'MC Dropout',\n",
       "  'Accuracy': '85.51%',\n",
       "  'Avg. Entropy ↓': '0.37',\n",
       "  'ECE ↓': '0.01'},\n",
       " {'Method': 'TTDA (Optional)',\n",
       "  'Accuracy': '82.61%',\n",
       "  'Avg. Entropy ↓': '0.44',\n",
       "  'ECE ↓': '0.01'},\n",
       " {'Method': 'Deep Ensemble',\n",
       "  'Accuracy': '88.02%',\n",
       "  'Avg. Entropy ↓': '0.46',\n",
       "  'ECE ↓': '0.06'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8a1f261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Accuracy Avg. Entropy ↓ ECE ↓\n",
      "Method                                          \n",
      "Softmax (Baseline)   85.51%           0.37  0.01\n",
      "MC Dropout           85.51%           0.37  0.01\n",
      "TTDA (Optional)      82.61%           0.44  0.01\n",
      "Deep Ensemble        88.02%           0.46  0.06\n",
      "EDL (Proposed)       92.68%           1.38  0.63\n",
      "TTDA                 82.61%           0.44  0.02\n",
      "TTDA                 82.68%           0.44  0.02\n",
      "MC Dropout           85.51%           0.37  0.01\n"
     ]
    }
   ],
   "source": [
    "results_df_2 = pd.DataFrame(results).set_index(\"Method\")\n",
    "print(results_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09f0db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Softmax \n",
    "torch.save(base_model.state_dict(), \"../models/softmax/softmax_model.pth\")\n",
    "\n",
    "# Save EDL model\n",
    "torch.save(edl_model.state_dict(), \"../models/edl/edl_model.pth\")\n",
    "\n",
    "# Save Deep Ensemble (save all models)\n",
    "for i, model in enumerate(ensemble_models):\n",
    "    torch.save(model.state_dict(), f\"../models/ensemble/ensemble_model_{i}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
